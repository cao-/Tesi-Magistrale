

In this section we present the first phase of a two-phase algorithm that aims to recover discontinuous functions from scattered data; the second phase will be disclosed in the following section.  This algorithm is mainly intended to demonstrate the applicability of the regularity classifier described in Chapter~\ref[classificationchap], and must not be viewed as a definitive solution to the problem. Anyhow, it seems to produce satisfactory results. The proposed method greatly takes inspiration from the kernel-based adaptive approximation algorithm outlined by Lenarduzzi and Shaback~\cite[lenarduzzi-shaback_2017] (henceforth simply referred to as L-S). We restrict our attention to the bidimensional case---even if the algorithm allows for a generalisation in arbitrary dimension---because in higher dimensions the required computational cost quickly becomes prohibitive.

The setting of the problem here is similar to that of L-S. Assume that a set~$X=\{\range x_N/\}\subset\Omega\subseteq ℝ^2\!$ of scattered data sites is given together with an associated set~$F=\{\range f_N/\}$ of function values, sampled from an unknown function~$f$.  Assume to know  that $f$ is continuous on certain non-overlapping subdomains~$\Omega_j\subseteq\Omega$, but not globally.  The goal is to recover the function~$f$ on the whole domain~$\smash{\Omega=\bigcup_{j=1}^M\Omega_j}$, starting from its sampled data~$(X, F)$. There will be no a priori assumptions on the form and placement of the singularities.



If a rough direct interpolation is attempted, without taking into account the discontinuities at the boundaries of the subdomains, then the reproduction quality  could be suboptimal--- the Gibbs phenomenon may appear along the boundaries (Fornberg and Flyer~\cite[fornberg-flyer_2012], Jae-Hun~\cite[jae_hun_2007]), and the discontinuity curves won't be outlined well.
One strategy to successfully recover such a discontinuous function is to first identify the different subdomains, or equivalently their boundaries, and then use this acquired knowledge to perform interpolation on each subdomain separately.  The main principle used here is that ``The approximation properties should determine the domains and their boundaries, not the other way round'' (L-S). First we determine the domains by inspecting the local regularity of the function, and then their boundaries as a consequence.

To implement locality, in L-S a $k$-d tree data structure is employed (Bentley~\cite[bentley_1975]). It is used as a cheap computational method to query for each point~$x\in\Omega$ its $n$ nearest neighbours from~$X$. Here, instead, we prefer to construct the Delaunay triangulation of the set~$X$ (see Aurenhammer, Kein and Lee~\cite[aurenhammer-klein-lee_2013]), because it provides information about the proximity of the points in a more structured way.  From the computational point of view, since we are dealing with an application in dimension~$2$, the difference between the two approaches is not substantial---they both require an average  time complexity of~$O(N\log N)$.  %An example of Delaunay triangulation is in Figure~\ref[delaunayfig]. 

\comment
\label[delaunayfig]
\topinsert
\picw=\hsize
\centerline{\inspic{delaunay.pdf}}
\cskip
\vskip-0.5em
\caption/f Delaunay triangulation for a set of $2^7$ points scattered in a rectangular domain.  The Delaunay triangulation has the property of  maximising the minimum angle, in the sense that the smallest angle of its triangles is at least as large as the smallest angle of the triangles in any other triangulation of the points; however, the Delaunay triangulation does not necessarily minimise the maximum angle.  The boundary of the triangulation is the convex hull of the set of points.
\bigskip
\endinsert
\endcomment




As centres for our local analysis we use the circumcentres~$C$ of the triangles~$T$ in the triangulation, differently from what is done in L-S, where the centres are the points of~$X$.  This is convenient, because in the Delaunay triangulation a circle circumscribing any triangle does not contain points of~$X$ in its interior, and consequently the set of the $n$ nearest points to a given circumcentre is guaranteed to contain all the vertices of its triangle, if $n\geq3$.  In this algorithm the number~$n$ of local points of~$X$ to consider is kept fixed, independently of the  analysed  circumcentre.  The set of the $n$~nearest points from~$X$ to a given circumcentre may be retrieved by taking advantage of the triangulation (like in Connor and Kumar~\cite[connor-kumar_2010]), or simply by resorting to the $k$-d tree structure.

We also fix a radial basis function~$\phi$ and a global shape parameter~$ε>0$. Since the goal is to detect discontinuities,  $\phi$ will be either the Wendland's or Matérn's $\Cal C^0$ function---anyhow,  basis functions with greater regularity can be used too, if higher order faults are to be detected.  Furthermore, we fix a tolerance~$\tau$, needed to build the regularity classifier~$\Cal R$, as in Definition~\ref[classifierdef].  The most important characteristic of this algorithm is that~{\em $\tau$ is chosen independently of the sampled function values~$F$}.  It must be experimentally tuned, but once tuned it can be used for any given data.


\def\lQ{\Bm Q_{\.c}}
\Red
First of all, the algorithm starts by selecting one single circumcentre~$c\in C$.  It can be either the first circumcentre of~$C$ (assuming to have an order on the set~$C$), or one circumcentre chosen at random. Then, the set~$X_c\subset X$ of its $n$ nearest neighbours from~$X$ is taken, together with its associated set~$F_c\subset F$ of function values. To assess the regularity of the local data~$(X_c, F_c)$, its $\phi$-regularity vector~$\lQ$ must be computed.

In order to obtain a good approximation of~$\lQ$ in the flat limit, while at the same time trying to avoid malconditioning in the interpolation system, prior to computation the global  parameter~$ε$ may be rescaled so that it better fits the local domain.  Specifically, if $d \coloneq \max_{x, y\in X_c}\norm{x-y}$~is the diameter of the local set~$X_c$ (value that can be obtained from the distance matrix of~$X_c$), the vector~$\lQ$ may actually be computed by using the scaled basis function~$\phi_δ$, with $δ\coloneq \slfrac εd$, instead of the globally defined function~$\phi_ε$.  But this additional scaling is not necessary if the data sites~$X$ are not too wildly scattered, in which case the same~$\phi_ε$ could be used for each local computation. Additionally, before computing~$\Bm Q_c$ it may be wise to bring the set of data values close to zero, by applying a translation $F_c\mapsto F_c - t$, as described in Section~\ref[numericalsec]. For instance, $t$ could be the mean of the values of~$F_c$ or simply the mean of the function values at the vertices of the triangle having circumcentre~$c$.  


After having obtained~$\lQ$, it is possible to evaluate the $\phi$-regularity classifier~$\Cal R$ on the data~$(X_c, F_c)$ by the expression
$$
\Cal R(X_c, F_c) = \cases{\!\phantom{-}1 & if $\norm{\lQ\!\.}_1 ≤ \tau$ \cr
                            \!-1 & if $\norm{\lQ\!\.}_1 > \tau$.}
$$
In order to proceed to the next step, the algorithm requires that~$R(X_c, F_c)=1$, which means that all the points of~$X_c$ presumably (up to the tolerance~$\tau$) belong to one single subdomain~$\Omega_j\subset\Omega$, where the sampled function~$f$ is continuous.  If this is not the case, then a different circumcentre must be tried.  After possibly a few trials, a good starting circumcentre should be found.  The number of trials should be low, under the assumption that each~$\Omega_j$ contains a moderate number of points, which of course must be bigger than~$n$.  If no starting point is found, then by exhaustion of all the circumcentres the algorithm prematurely terminates. This eventuality signals that either the parameter~$\tau$ was set too restrictive, or the sample~$(X, F)$ does not contain enough points in each subdomain~$\Omega_j$ where $f$ is continuous.  We now assume to have found a circumcentre~$c$ such that~$\Cal R(X_c, F_c) = 1$, and use it to proceed to the next step.


Provided that the classification was right, the set~$X_c$ is fully contained in one single subdomain~$\Omega_j$.  The goal now is to try and extend~$X_c$ up to the set~$X\cap\Omega_j$, made of all the data sites contained in~$\Omega_j$.  Let us call $\smash{T_c^{\,\Cal i}}$ the set of all the triangles ``inside''~$X_c$, and $\smash{T_c^{\,\Cal b}}$ the set of all the triangles at the ``border'' of~$X_c$, i.e.,
$$
T_c^{\,\Cal i}\coloneq \{\,t\in T\>:\>\, V(t) \subset X_c\,\},\qquad T_c^{\,\Cal b}\coloneq \{\,t\in T\>:\>\, V(t)\cap X_c\neq V(t),\emptyset\,\},
$$
where~$V(t)$ denotes the three vertices of the triangle~$t$.  Simply speaking, $T_c^{\,\Cal i}$ is the set of triangles of~$T$ whose vertices belong to~$X_c$; and $T_c^{\,\Cal b}$ is the set of triangles of~$T$ that have some but not all vertices in~$X_c$.  The union of the triangles $T_c^{\.\Cal i}$ can be viewed as the realisation  of the discrete set of points~$X_c$ as a subdomain of~$\Omega$; and the union of the triangles~$T_c^{\,\Cal b}$ as a fat version of the border of this local subdomain. Refer to Figure~\ref[patchfig] to visualise a concrete example. % Patch


Let us also define $\Cal I_j$ as the current set of internal triangles, and $\Cal B_j$ as the current set of triangles at the border.  They are initialised as $\smash{\Cal I_j \coloneq T_c^{\,\Cal i}}$ and~$\smash{\Cal B_j \coloneq T_c^{\,\Cal b}}$, but later they will be updated when the regular domain gets expanded. Moreover, we progressively keep track in the set~$\smash{\Cal D_j}$ of triangles that can't become part of~$\Cal B_j$---initially we simply assign~$\Cal D_j\coloneq\emptyset$.  Finally, we store in the computer memory $X_c$ (actually, just the indices of $X_c$ in the ordered set~$X$) and also the function that associates to each element of~$\Cal B_j$ the set~$X_c$.  This function serves as a way to remind that the triangles currently in~$\Cal B_j$ are located at the border of the domain of triangles with vertices in~$X_c$.  


\label[patchfig]
\topinsert
\picw = \hsize
\centerline{\inspic{patch.pdf}}
\caption/f
A portion of a set $X\subset\Omega$ of data sites and its Delaunay triangulation.  The red cross and the blue triangle are respectively the selected circumcentre~$c\in C$ and its triangle. It is here represented also the circle of centre~$c$ and radius~$r\coloneq \max_{x\in X_c}\norm{x-c}$, which is the smallest circle centred at~$c$ that contains all the points~$X_c$.  Its radius~$r$ depends on the chosen circumcentre~$c$, so it is not a globally fixed parameter: what is fixed is the number of points of~$X_c$---in  this example $n=|X_c|=100$.  The set~$T_c^{\,\Cal i}$ is the set of green triangles, while the set~$T_c^{\,\Cal b}$ is that of yellow triangles. 
\endinsert

Now the main loop begins, where we iteratively consider a new centre~$c\in C$ from the circumcentres of the triangles in~$\Cal B_j$, and try from that position to extend the domain~$\Cal I_j$.  Let us pretend to be at a general entry point to the loop, where
\begitems
* $\Cal I_j$ is a set of triangles that represent the triangulation of the so far constructed piece of the subdomain~$\Omega_j\subset\Omega$, and $\Cal B_j$ is the set of triangles at the border of~$\Cal I_j$ (initially $\Cal I_j$ and~$\Cal B_j$ are just the sets defined above);
* Each set~$X_c$ that previously passed the classification step has been stored (in the first part of the algorithm we stored just one such set~$X_c$);
* There is a map that associates each triangle~$t\in\Cal B_j$ to the collection of the stored sets of points~$X_c$ which satisfy~$\smash{t\in T_c^{\,\Cal b}}$ (one single triangle $t$ may be at the border of more than one set of points~$X_c$).
\enditems
The decision to either enter the loop or terminate it depends on the content of~$\Cal B_j$, whether it is empty or not.


\label[removefig]
\topinsert
\picw=\hsize
\centerline{\inspic{general.pdf}}
\cskip
\vskip-0.9em
\caption/f
This picture visualises a portion of a set~$X\subset\Omega$ of data sites with its triangulation, where~$\Omega=[0,1]\times[0,1]\subset\R^2\!\!$.\, The sampled function~$f$ is discontinuous, and the black dashed line represents its discontinuity curve that separates~$\Omega$ into two subdomains.  Here we are at a general point of the algorithm, where the green, yellow, and red triangles are respectively the set $\Cal I_j$, $\Cal B_j$, and~$\Cal D_j$.  The blue triangle is the triangle~$\smash{t'\in\Cal B_j}$ that is currently being analysed.  The red circle, centred at the circumcentre~$\smash{c'}$ (the red cross) of~$t'$, encloses the set of the~$n$ nearest points to~$\smash{c'}$ taken from~$X$ (in this example $n = 100$).
The small black circles are the points of~$X_{c'}$ that must not be removed from it---this is the set that we called~$Z$.  Notice that $Z$ need not be equal to the intersection of~$X_{c'}$ with the vertices of the green triangles.
  The small red circle is the point~$p\in X_{c'}\setminus Z$ that has the maximum value in the associated entry of the vector~$\Bm Q_{c'}$;  the blue dashed line delimits the open half plane~$\Pi$ that does not contain~$\smash{c'}$.
  In this case, after when the points of~$(X_{c'}\cap \Pi)\setminus Z$ are removed from~$X_{c'}$, the new set~$X_{c'}$ is fully contained in~$\Omega_j$, so the classifier~$\Cal R(X_{c'}, F_{c'})$ hopefully evaluates to~$1$,  and the set of triangles~$\smash{T_{c'}^{\,\cal i}}$ is added to the set~$\Cal I_j$ of green triangles.  Moreover, also the set~$\Cal B_j$ of yellow triangles is updated to reflect the new border of~$\Cal I_j$.
\bigskip
\endinsert

If $\Cal B_j=\emptyset$, then the so far constructed domain~$\Cal I_j$ has no more possible extension points, so (if every classification was correct) all the points of the subdomain~$\Omega_j$ have already been collected within the set of triangles~$\Cal I_j$ (as the vertices of those triangles), and the first subdomain~$\Omega_j$ has been determined. Then, in order to determine the other subdomains of~$\Omega$, the whole algorithm is repeated again, by starting from one of the remaining triangles, which are the triangles not belonging to~$\Cal I_j$. This process is repeated again and again until all the triangles of~$T$ have been exhausted, and a collection of sets~$\smash{\{\Cal I_j\}_{j=1}^M}$ which define the different subdomains~$\smash{\{\Omega_j\}_{j=1}^M}$ has been found.  At this point we terminate the algorithm by returning the triangulations~$\smash{\{\Cal I_j\}_{j=1}^M}$.


If instead $\Cal B_j\neq \emptyset$, then we can select one new triangle~$t'\in \Cal B_j$ (which one we choose doesn't matter) and its circumcentre~$\smash{c'}$, and try to extend~$\Cal I_j$ from this position. To do so, we consider again the set~$X_{c'}$ of the $n$ nearest neighbours to~$\smash{c'}$ taken from~$X$, with the corresponding set~$F_{c'}$ of function values, and compute the regularity vector~$\Bm Q_{c'}$ as before. We can then classify the data~$(X_{c'}, F_{c'})$ by evaluating $\Cal R(X_{c'}, F_{c'})$. If the classifier evaluates to~$1$, it means that (according to the tolerance~$\tau$) each point of~$X_{c'}$ must belong to~$\Omega_j$, and so we extend~$\Cal I_j$ by adding to it the set~$\smash{T_{c'}^{\.\cal i}}$ of triangles with vertices in~$X_{c'}$ (most probably, some of these triangles already belong to~$\Cal I_j$), and then also we change~$\Cal B_j$ by removing from it the triangle~$t'$ and adding to it the triangles $\smash{T_{c'}^{\.\cal b}}\setminus(\Cal D_j\cup \Cal I_j)$; if the classifier evaluates to~$0$, it means that there are points in~$X_{c'}$ belonging to a subdomain of~$\Omega$ different from~$\Omega_j$.  We have to remove those points and keep only the ones that belong to~$\Omega_j$.


We need a way to efficiently remove all the points of~$X_{c'}$ located outside of~$\Omega_j$ and at the same time try to keep the most possible points of~$X_{c'}$ that are contained in~$\Omega_j$.  A possible strategy is described here.  First we retrieve from the computer memory all the stored sets~$X_c$  such that~$\smash{t'\in T_{c}^{\.\cal b}}$, and let~$Y$ be their union.  Certainly, we don't want to remove from~$X_{c'}$ any of the points of~$Y$ (because $Y$ is in the domain~$\Cal I_j$ that we are trying to extend), nor the vertices of the triangle~$\smash{t'}$ (because we are trying to extend $\Cal I_j$ by adding at least~$t'$).  Let~$Z\coloneq (Y\cup V(t'))\cap X_{c'}$ be the set of points of~$X_{c'}$ that must not be removed. To actually have a clue about which points of~$X_{c'}\setminus Z$ should be removed from~$X_{c'}$, we can look at the entries of the previously computed vector~$\Bm Q_{c'}$.  The points of~$X_{c'}$ close to the boundary of~$\Omega_j$ are the ones that have the largest associated value in the vector~$\Bm Q_{c'}$. We thus take the point $p\in X_{c'}\setminus Z$ that have the maximum value in~$\Bm Q_{c'}$, and  consider the open half plane
$$
\Pi\coloneq \{\,x\in \Omega\,:\>\langle\. p - c',\, x- p\rangle > 0\}
$$
determined by the line passing from~$p$ and perpendicular to the vector~$x-p$, and not containing the point~$c'$. Finally we update~$X_{c'}$ by removing from it the set of points~$(X_{c'}\cap\Pi)\setminus Z$.  Figure~\ref[removefig] should help understanding this part.


In case $(X_{c'}\cap\Pi)\setminus Z=\emptyset$ (that is, in case we didn't remove any point from~$X_{c'}$), we remove from~$X_{c'}$ the point~$p$.  We then compute again~$\Bm Q_{c'}$ and use it to evaluate~$\Cal R(X_{c'}, F_{c'})$, until it finally happens that~$\Cal R(X_{c'}, F_{c'})=1$ and so that the reduced set~$X_{c'}$  can be used to extend~$\cal I$. Then  $\Cal I_j$ gets actually extended by adding to it the set~$\smash{T_{c'}^{\.\cal i}}$, and after that also the set~$\Cal B$ is updated by removing from it the triangles of~$\smash{T_{c'}^{\.\cal i}}$ and adding to it the triangles~$\smash{T_{c'}^{\.\cal b}}\setminus(\Cal D_j\cup \Cal I_j)$.
If instead $\Cal R(X_{c'}, F_{c'})$ is always~$0$ no matter how many points we remove from~$X_{c'}$ (and all the possible points have been already removed), then we simply remove~$\smash{t'}$ from the set~$\Cal B_j$ of boundary triangles, and add it to the set~$\Cal D_j$.  This means that from the triangle~$\smash{t'}$ we won't attempt anymore to extend~$\Cal I_j$.
After having updated both $\Cal I_j$ and~$\Cal B_j$, the entering condition of the loop is tested again and eventually another cycle is performed. 

\Black




A full implementation of the described algorithm, written in the MATLAB language, is available at GitHub~\cite[github-algorithm].  


% The local discrete domain, namely the set of points~$X_C$, can be turned into an actual subdomain of~$\Omega$ by taking the union of all the triangles of~$T$ that have all the vertices in~$X_C$. 

% To .... clear, the full algorithm is summed up in a pseudocode language.



\nonum\secc Examples
